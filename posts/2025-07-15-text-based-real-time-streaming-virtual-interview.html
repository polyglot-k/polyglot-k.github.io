<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spring WebFlux와 Redis로 구축한 LLM 스트리밍 파이프라인 | Polyglot-K의 블로그</title>
    <meta name="generator" content="VuePress 1.9.10">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.min.css">
    <meta name="description" content="다양한 도전을 즐기는 개발자 Polyglot-K의 블로그입니다.">
    
    <link rel="preload" href="/assets/css/0.styles.6efed9ee.css" as="style"><link rel="preload" href="/assets/js/app.3e0c7978.js" as="script"><link rel="preload" href="/assets/js/2.e2e96b39.js" as="script"><link rel="preload" href="/assets/js/1.49846db0.js" as="script"><link rel="preload" href="/assets/js/24.c58c220f.js" as="script"><link rel="prefetch" href="/assets/js/10.1e3fe773.js"><link rel="prefetch" href="/assets/js/11.56e5a865.js"><link rel="prefetch" href="/assets/js/12.1aa3b0c3.js"><link rel="prefetch" href="/assets/js/13.1dd11157.js"><link rel="prefetch" href="/assets/js/14.0122fd01.js"><link rel="prefetch" href="/assets/js/15.18ef8915.js"><link rel="prefetch" href="/assets/js/16.98147816.js"><link rel="prefetch" href="/assets/js/17.46fff286.js"><link rel="prefetch" href="/assets/js/18.a9838e2e.js"><link rel="prefetch" href="/assets/js/19.34738524.js"><link rel="prefetch" href="/assets/js/20.27ef86b3.js"><link rel="prefetch" href="/assets/js/21.c7b8d009.js"><link rel="prefetch" href="/assets/js/22.f84154f0.js"><link rel="prefetch" href="/assets/js/23.fbc1d3ff.js"><link rel="prefetch" href="/assets/js/25.8c8a0afd.js"><link rel="prefetch" href="/assets/js/26.e0bcc60b.js"><link rel="prefetch" href="/assets/js/27.017d7e2a.js"><link rel="prefetch" href="/assets/js/3.75064c1e.js"><link rel="prefetch" href="/assets/js/4.2afe5cdc.js"><link rel="prefetch" href="/assets/js/5.a37b361e.js"><link rel="prefetch" href="/assets/js/6.c34bda13.js"><link rel="prefetch" href="/assets/js/7.b04f2031.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.6fed1ae2.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6efed9ee.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Polyglot-K의 블로그</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/posts/2025-08-25-spring-webflux-performance.html" class="nav-link">
  Posts
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/posts/2025-08-25-spring-webflux-performance.html" class="nav-link">
  Posts
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>게시물 목록</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/posts/2025-08-25-spring-webflux-performance.html" class="sidebar-link">Spring Webflux 애플리케이션 성능 병목 분석 및 38배 개선기</a></li><li><a href="/posts/2025-08-10-scheduler-mq-data-archiving.html" class="sidebar-link">아웃박스 패턴을 통한 중간 상태 데이터 관리와 복원 가능한 배치 설계</a></li><li><a href="/posts/2025-08-05-valkey-concurrency-issue.html" class="sidebar-link">Redis Lua 스크립트를 활용한 동시성 제어와 좌석 선점 로직 개선기</a></li><li><a href="/posts/2025-07-20-ice-breaking-platform.html" class="sidebar-link">Redis Pub/Sub 으로 분산 실시간 상태 머신 구현하기</a></li><li><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html" aria-current="page" class="active sidebar-link">Spring WebFlux와 Redis로 구축한 LLM 스트리밍 파이프라인</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#_1️⃣-아키텍처-설계-선택의-이유" class="sidebar-link">1️⃣ 아키텍처 설계 — 선택의 이유</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#webflux-비동기-i-o의-필연성" class="sidebar-link">WebFlux: 비동기 I/O의 필연성</a></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#sse-단방향-스트리밍의-합리적-선택" class="sidebar-link">SSE: 단방향 스트리밍의 합리적 선택</a></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#langchain4j-gemini-api와의-직접-연동" class="sidebar-link">LangChain4j: Gemini API와의 직접 연동</a></li></ul></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#_2️⃣-문제와-해결" class="sidebar-link">2️⃣ 문제와 해결</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#스트림-끊김-하트비트로-연결-유지" class="sidebar-link">스트림 끊김 — 하트비트로 연결 유지</a></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#chunk-단위-저장으로-인한-db-부하-redis-임시-버퍼로-완화" class="sidebar-link">Chunk 단위 저장으로 인한 DB 부하 — Redis 임시 버퍼로 완화</a></li></ul></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#_3️⃣-트레이드오프와-사이드이펙트" class="sidebar-link">3️⃣ 트레이드오프와 사이드이펙트</a></li><li class="sidebar-sub-header"><a href="/posts/2025-07-15-text-based-real-time-streaming-virtual-interview.html#_4️⃣-마무리하며" class="sidebar-link">4️⃣ 마무리하며</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="spring-webflux와-redis로-구축한-llm-스트리밍-파이프라인"><a href="#spring-webflux와-redis로-구축한-llm-스트리밍-파이프라인" class="header-anchor">#</a> Spring WebFlux와 Redis로 구축한 LLM 스트리밍 파이프라인</h1> <p>AI 기반 대화형 서비스에서 핵심은 <strong>응답 속도</strong>와 <strong>대화의 자연스러움</strong>이다.
“AI 면접관” 프로젝트를 시작할 때 세운 원칙은 단 하나였다.</p> <blockquote><p><strong>“AI와의 대화는 사람과의 대화처럼 자연스러워야 한다.”</strong></p></blockquote> <p>이 목표는 단순히 빠른 응답을 반환하는 것을 넘어,
AI가 <strong>‘생각하며 말하는 듯한 실시간 스트리밍 경험’</strong> 을 구현해야 한다는 기술적 과제로 이어졌다.</p> <h2 id="_1️⃣-아키텍처-설계-선택의-이유"><a href="#_1️⃣-아키텍처-설계-선택의-이유" class="header-anchor">#</a> 1️⃣ 아키텍처 설계 — 선택의 이유</h2> <h3 id="webflux-비동기-i-o의-필연성"><a href="#webflux-비동기-i-o의-필연성" class="header-anchor">#</a> WebFlux: 비동기 I/O의 필연성</h3> <p>LLM 응답은 특성상 수 초 이상 지연되는 경우가 많다.
기존 Spring MVC의 스레드-퍼-리퀘스트 모델은 이런 장기 연결 요청에서 병목을 초래했다.</p> <p>WebFlux는 소수의 논블로킹 스레드로 수천 개의 요청을 동시에 처리할 수 있다.
즉, 요청마다 스레드를 점유하지 않아 <strong>높은 동시성 환경에서도 안정적인 처리량</strong>을 확보할 수 있었다.</p> <p>이 선택의 트레이드오프는 명확했다.
비동기 처리를 도입함으로써 디버깅이 복잡해지고, 코드 가독성이 떨어질 수 있다.
하지만, <strong>응답 대기 시간이 긴 LLM 요청의 특성상 WebFlux는 필연적인 선택</strong>이었다.</p> <h3 id="sse-단방향-스트리밍의-합리적-선택"><a href="#sse-단방향-스트리밍의-합리적-선택" class="header-anchor">#</a> SSE: 단방향 스트리밍의 합리적 선택</h3> <p>AI 응답은 “서버 → 클라이언트”로만 흐른다.
따라서 양방향 통신(WebSocket)보다는 <strong>HTTP 기반의 단방향 스트리밍 프로토콜인 SSE(Server-Sent Events)</strong> 가 훨씬 단순하고 효율적이었다.</p> <p>SSE는 별도의 프로토콜 업그레이드 없이 브라우저 기본 API(<code>EventSource</code>)로 바로 사용할 수 있으며,
자동 재연결 기능을 지원해 안정성이 높다.</p> <p>이 선택은 구조를 단순화했지만, 동시에 <strong>바이너리 데이터 전송 불가</strong>라는 제약도 함께 가져왔다.
텍스트 기반 응답만 다루는 LLM 서비스이기에, 이는 충분히 감수할 수 있는 범위였다.</p> <h3 id="langchain4j-gemini-api와의-직접-연동"><a href="#langchain4j-gemini-api와의-직접-연동" class="header-anchor">#</a> LangChain4j: Gemini API와의 직접 연동</h3> <p>당시 Spring AI는 Google Gemini의 스트리밍 API를 직접 지원하지 않았다.
따라서 LLM 호출은 <strong>LangChain4j</strong>를 사용하여 처리했다.</p> <p>LangChain4j는 Gemini의 토큰 단위 스트리밍(<code>TokenStream</code>)을 그대로 지원하며,
향후 다른 LLM과의 체이닝 구조로 확장하기에도 유리했다.</p> <p>이를 통해 AI가 한 번에 문장을 내뱉는 대신,
<strong>“조금씩 말하면서 생각하는 듯한” 자연스러운 사용자 경험</strong>을 구현할 수 있었다.</p> <h2 id="_2️⃣-문제와-해결"><a href="#_2️⃣-문제와-해결" class="header-anchor">#</a> 2️⃣ 문제와 해결</h2> <h3 id="스트림-끊김-하트비트로-연결-유지"><a href="#스트림-끊김-하트비트로-연결-유지" class="header-anchor">#</a> 스트림 끊김 — 하트비트로 연결 유지</h3> <p>개발 초기, 약 30초 이상 응답이 지속되면 스트림이 조용히 끊어지는 문제가 발생했다.
원인은 로드밸런서의 idle timeout이었다.</p> <p>이 문제를 해결하기 위해, <strong>주기적으로 하트비트(:heartbeat) 이벤트를 전송</strong>하도록 했다.
하트비트는 클라이언트 화면에는 표시되지 않지만,
TCP 연결을 유지시키는 역할을 수행했다.</p> <p>이 단순한 개선으로 스트림 연결 안정성이 크게 높아졌고,
서버나 네트워크 환경에 관계없이 지속적인 스트리밍이 가능해졌다.</p> <h3 id="chunk-단위-저장으로-인한-db-부하-redis-임시-버퍼로-완화"><a href="#chunk-단위-저장으로-인한-db-부하-redis-임시-버퍼로-완화" class="header-anchor">#</a> Chunk 단위 저장으로 인한 DB 부하 — Redis 임시 버퍼로 완화</h3> <p>LLM 응답은 수백 개의 토큰으로 나뉘어 전송된다.
초기에는 각 토큰(Chunk)마다 DB에 저장하는 구조였는데,
이로 인해 <strong>지속적인 I/O 부하</strong>가 발생했다.</p> <p>이를 해결하기 위해 Redis를 <strong>임시 버퍼</strong>로 사용했다.</p> <p>응답이 생성되는 동안 Redis에 Chunk 데이터를 순차적으로 누적하고,
모든 응답이 완료된 시점에 한 번만 DB에 반영하도록 구조를 변경했다.</p> <p>이 접근으로 DB I/O 부하를 대폭 줄였으며,
특히 다수의 동시 스트리밍 요청에서도 안정적인 처리 성능을 확보할 수 있었다.</p> <h2 id="_3️⃣-트레이드오프와-사이드이펙트"><a href="#_3️⃣-트레이드오프와-사이드이펙트" class="header-anchor">#</a> 3️⃣ 트레이드오프와 사이드이펙트</h2> <table><thead><tr><th>선택</th> <th>장점</th> <th>사이드이펙트</th></tr></thead> <tbody><tr><td>WebFlux</td> <td>높은 동시성 처리</td> <td>디버깅 및 스택 추적 난이도 증가</td></tr> <tr><td>SSE</td> <td>단순한 구조, 브라우저 호환성</td> <td>바이너리 전송 불가</td></tr> <tr><td>Redis 버퍼</td> <td>I/O 부하 감소</td> <td>TTL 관리 실패 시 데이터 유실 가능성</td></tr> <tr><td>하트비트 유지</td> <td>연결 안정성 향상</td> <td>네트워크 트래픽 소폭 증가</td></tr></tbody></table> <p>결국 모든 선택은 “대화의 자연스러움”이라는 목표를 달성하기 위한 트레이드오프였다.
WebFlux의 복잡함, Redis TTL의 관리 리스크를 감수하더라도
사용자가 <strong>‘생각하는 AI’와 대화하는 경험</strong>을 제공하는 것이 더 큰 가치였다.</p> <h2 id="_4️⃣-마무리하며"><a href="#_4️⃣-마무리하며" class="header-anchor">#</a> 4️⃣ 마무리하며</h2> <p>이 파이프라인을 통해 단순한 “응답 반환”을 넘어,
AI가 <strong>실시간으로 사고하고 말하는 듯한 대화 경험</strong>을 구현할 수 있었다.</p> <p>WebFlux는 비동기 처리의 복잡함을 동반하지만,
Reactive Stream의 철학을 이해하고 Redis를 적절히 조합하면
<strong>확장성과 자연스러움</strong>을 모두 잡을 수 있다.</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/posts/2025-07-20-ice-breaking-platform.html" class="prev">
        Redis Pub/Sub 으로 분산 실시간 상태 머신 구현하기
      </a></span> <!----></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.3e0c7978.js" defer></script><script src="/assets/js/2.e2e96b39.js" defer></script><script src="/assets/js/1.49846db0.js" defer></script><script src="/assets/js/24.c58c220f.js" defer></script>
  </body>
</html>
